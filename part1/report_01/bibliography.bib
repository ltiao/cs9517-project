@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {Lowe, David G},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:Users/tiao/Downloads/art\%3A10.1023\%2FB\%3AVISI.0000029664.99615.94.pdf:pdf},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
number = {2},
pages = {91--110},
pmid = {20064111},
title = {{Distinctive image features from scale-invariant keypoints}},
volume = {60},
year = {2004}
}
@inproceedings{Rublee2011,
abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126544},
file = {:Users/tiao/Downloads/06126544.pdf:pdf},
isbn = {9781457711015},
issn = {1550-5499},
pages = {2564--2571},
pmid = {20033598},
title = {{ORB: An efficient alternative to SIFT or SURF}},
year = {2011}
}
@inproceedings{Rosten2006,
abstract = {Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7\% of the available processing time. By comparison neither the Harris detector (120\%) nor the detection stage of SIFT (300\%) can operate at full frame rate. Clearly a high-speed detector is of limited use if the features produced are unsuitable for downstream processing. In particular, the same scene viewed from two different positions should yield features which correspond to the same real-world 3D locations [1]. Hence the second contribution of this paper is a comparison corner detectors based on this criterion applied to 3D scenes. This comparison supports a number of claims made elsewhere concerning existing corner detectors. Further, contrary to our initial expectations, we show that despite being principally constructed for speed, our detector significantly outperforms existing feature detectors according to this criterion.},
author = {Rosten, Edward and Drummond, Tom},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/11744023\_34},
file = {:Users/tiao/Downloads/chp\%3A10.1007\%2F11744023\_34.pdf:pdf},
isbn = {3540338322},
issn = {03029743},
pages = {430--443},
pmid = {18684738},
title = {{Machine learning for high-speed corner detection}},
volume = {3951 LNCS},
year = {2006}
}
@inproceedings{Calonder2010,
abstract = {We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF. We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L(2) norm as is usually done. As a result, BRIEF is very fast both to build and to match. We compare it against SURF and U-SURF on standard benchmarks and show that it yields a similar or better recognition performance, while running in a fraction of the time required by either.},
author = {Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-15561-1\_56},
file = {:Users/tiao/Downloads/chp\%3A10.1007\%2F978-3-642-15561-1\_56.pdf:pdf},
isbn = {364215560X},
issn = {03029743},
number = {PART 4},
pages = {778--792},
pmid = {19500939},
title = {{BRIEF: Binary robust independent elementary features}},
volume = {6314 LNCS},
year = {2010}
}
@article{Bay2008,
abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision. ?? 2007 Elsevier Inc. All rights reserved.},
author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and {Van Gool}, Luc},
doi = {10.1016/j.cviu.2007.09.014},
file = {:Users/tiao/Downloads/1-s2.0-S1077314207001555-main.pdf:pdf},
isbn = {9783540338321},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Camera calibration,Feature description,Interest points,Local features,Object recognition},
number = {3},
pages = {346--359},
pmid = {16081019},
title = {{Speeded-Up Robust Features (SURF)}},
volume = {110},
year = {2008}
}
